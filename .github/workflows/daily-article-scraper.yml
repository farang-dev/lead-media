name: Daily Article Scraper

on:
  schedule:
    # Run daily at 7:00 AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allows manual triggering from GitHub UI

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          ref: main

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: false

      # Use npm install instead of npm ci to avoid requiring a lock file
      - name: Install dependencies
        run: npm install

      - name: Run article scraper and publisher
        run: node scripts/test-full-process.js
        env:
          # WordPress.com API Configuration
          WORDPRESS_API_URL: "https://public-api.wordpress.com/wp/v2/sites/fumixo5.wordpress.com"
          WORDPRESS_USERNAME: "fuminozawa246"
          WORDPRESS_PASSWORD: ${{ secrets.WORDPRESS_PASSWORD }}
          # WordPress.com OAuth credentials - use the exact client ID from your .env file
          WORDPRESS_CLIENT_ID: "116326"
          WORDPRESS_CLIENT_SECRET: "cco4aWs2AeuymIIY0pWcFGtqawHWgs7Nl4KeRAVfOyIMM4MwVob0Er7TNtWnusHL"

          # OpenRouter API Configuration
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}

          # Site URL
          NEXT_PUBLIC_SITE_URL: ${{ secrets.NEXT_PUBLIC_SITE_URL }}

          # Target website to scrape (optional)
          TARGET_WEBSITE: https://techcrunch.com/category/artificial-intelligence/

      # Sitemap generation and pushing removed to avoid permission issues
