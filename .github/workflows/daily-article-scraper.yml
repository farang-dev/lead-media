name: Daily Article Scraper

on:
  schedule:
    # Run daily at 7:00 AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allows manual triggering from GitHub UI

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          ref: main

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      # Use npm install instead of npm ci to avoid requiring a lock file
      - name: Install dependencies
        run: npm install

      - name: Run article scraper and publisher
        run: node scripts/test-full-process.js
        env:
          # WordPress.com API Configuration
          WORDPRESS_API_URL: "https://public-api.wordpress.com/wp/v2/sites/fumixo5.wordpress.com"
          WORDPRESS_USERNAME: "fuminozawa246"
          WORDPRESS_PASSWORD: ${{ secrets.WORDPRESS_PASSWORD }}
          # WordPress.com OAuth credentials
          WORDPRESS_CLIENT_ID: "116326"
          WORDPRESS_CLIENT_SECRET: ${{ secrets.WORDPRESS_CLIENT_SECRET }}

          # OpenRouter API Configuration
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}

          # Site URL
          NEXT_PUBLIC_SITE_URL: ${{ secrets.NEXT_PUBLIC_SITE_URL }}

          # Target website to scrape (optional)
          TARGET_WEBSITE: https://techcrunch.com/category/artificial-intelligence/

      - name: Generate sitemap
        run: node scripts/generate-sitemap.js
        env:
          WORDPRESS_API_URL: "https://public-api.wordpress.com/wp/v2/sites/fumixo5.wordpress.com"
          NEXT_PUBLIC_SITE_URL: "https://www.unmanned-newsroom.com/"

      - name: Commit and push sitemap changes
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          git add public/sitemap.xml
          git commit -m "Update sitemap with latest articles" || echo "No changes to commit"
          git push
